{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJn0T/eYqFepK5jl6rVS2O"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import autograd\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCSP9mknqabW",
        "outputId": "b8dc31c3-18c2-42ea-8477-37497ca71950"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a576a23fe70>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction to Torch's tensor library"
      ],
      "metadata": {
        "id": "slCmoHRpsPpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tensors\n",
        "\n",
        "V_data = [1., 2., 3.]\n",
        "V = torch.Tensor(V_data)\n",
        "print(V)\n",
        "\n",
        "# create a matrix\n",
        "\n",
        "M_data = [[1., 2., 3.], [4., 5., 6.]]\n",
        "M = torch.Tensor(M_data)\n",
        "print(M)\n",
        "\n",
        "# create 3d tensor\n",
        "T_data = [[[1., 2.], [3., 4.],\n",
        "           [5., 6.], [7., 8.]]]\n",
        "T = torch.Tensor(T_data)\n",
        "print(T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwblEGC6sESB",
        "outputId": "3c5ef463-fe2f-4810-80d9-54d15bb893b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([[[1., 2.],\n",
            "         [3., 4.],\n",
            "         [5., 6.],\n",
            "         [7., 8.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_tensor = torch.Tensor([[1, 2, 3, 4], [0, 0, 0, 0]])\n",
        "print(tmp_tensor.shape)\n",
        "tmp_tensor = torch.Tensor([[[1, 2, 3],\n",
        "                            [0, 0, 0]]])\n",
        "print(tmp_tensor.shape)"
      ],
      "metadata": {
        "id": "NcQ8s3zOsdbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e8fcf3-62c7-4790-8a4b-a54a3dedac19"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4])\n",
            "torch.Size([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(V[0])\n",
        "print(M[0])\n",
        "print(T[0])"
      ],
      "metadata": {
        "id": "cOZ1nK5ytRWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c945df94-d1ea-431c-8ea3-100a08c15755"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.)\n",
            "tensor([1., 2., 3.])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.],\n",
            "        [7., 8.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, 4, 5)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mms1NfXvWyS",
        "outputId": "e734a9d0-7bee-4645-f9cb-8283fc4d7e3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.5256, -0.7502, -0.6540, -1.6095, -0.1002],\n",
            "         [-0.6092, -0.9798, -1.6091, -0.7121,  0.3037],\n",
            "         [-0.7773, -0.2515, -0.2223,  1.6871,  0.2284],\n",
            "         [ 0.4676, -0.6970, -1.1608,  0.6995,  0.1991]],\n",
            "\n",
            "        [[ 0.8657,  0.2444, -0.6629,  0.8073,  1.1017],\n",
            "         [-0.1759, -2.2456, -1.4465,  0.0612, -0.6177],\n",
            "         [-0.7981, -0.1316,  1.8793, -0.0721,  0.1578],\n",
            "         [-0.7735,  0.1991,  0.0457,  0.1530, -0.4757]],\n",
            "\n",
            "        [[-0.1110,  0.2927, -0.1578, -0.0288,  0.4533],\n",
            "         [ 1.1422,  0.2486, -1.7754, -0.0255, -1.0233],\n",
            "         [-0.5962, -1.0055,  0.4285,  1.4761, -1.7869],\n",
            "         [ 1.6103, -0.7040, -0.1853, -0.9962, -0.8313]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor operations\n",
        "x = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
        "y = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
        "z = x + y\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uny5FWmvvdEd",
        "outputId": "2a359dcd-a797-4c05-a671-fb201a475e83"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 7., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_1 = torch.randn(2, 5)\n",
        "y_1 = torch.randn(3, 5)\n",
        "z_1 = torch.cat([x_1, y_1])\n",
        "print(z_1.shape)\n",
        "\n",
        "x_2 = torch.randn(2, 6)\n",
        "y_2 = torch.randn(2, 8)\n",
        "z_2 = torch.cat([x_2, y_2], 1)\n",
        "print(z_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlPT0r9YwNQC",
        "outputId": "0f413dce-b32a-4fd5-9f49-fd581c8998d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 5])\n",
            "torch.Size([2, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping tensor\n",
        "x = torch.randn(2, 3, 4)\n",
        "print(x.shape)\n",
        "print(x.view(2, 12).shape)\n",
        "print(x.view(2, -1).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63sX0e5Uwh2W",
        "outputId": "d3084599-e887-43e0-e929-b742a8436e89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4])\n",
            "torch.Size([2, 12])\n",
            "torch.Size([2, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Computation Graphs and Automatic Differentiation"
      ],
      "metadata": {
        "id": "Ng7x2_E2xTMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables wrap tensor objects\n",
        "x = autograd.Variable(torch.Tensor([1., 2., 3.]), requires_grad=True)\n",
        "print(x.data)\n",
        "\n",
        "# also can do tensor operation\n",
        "y = autograd.Variable(torch.Tensor([4., 5., 6.]), requires_grad=True)\n",
        "z = x + y\n",
        "print(z.data)\n",
        "\n",
        "# but z knows something extra\n",
        "print(z.grad_fn)"
      ],
      "metadata": {
        "id": "6hwvlMKUxOuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23ffd43-ec6f-4dc1-d7bd-1ece76c07346"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([5., 7., 9.])\n",
            "<AddBackward0 object at 0x7a56a1cdb8e0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets sum up all the entries in z\n",
        "s = z.sum()\n",
        "print(s)\n",
        "print(s.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K534OPu3xAx",
        "outputId": "cd2c1354-1728-46f4-fda0-d4ebae7272f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(21., grad_fn=<SumBackward0>)\n",
            "<SumBackward0 object at 0x7a56a1cdb490>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnY9zzgw4DaK",
        "outputId": "c7867720-15d9-4bd5-8f2f-f04070963191"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((2, 2))\n",
        "y = torch.randn((2, 2))\n",
        "z = x + y\n",
        "\n",
        "var_x = autograd.Variable(x, requires_grad=True)\n",
        "var_y = autograd.Variable(y, requires_grad=True)\n",
        "var_z = var_x + var_y\n",
        "print(var_z.grad_fn)\n",
        "\n",
        "var_z_data = var_z.data\n",
        "new_var_z = autograd.Variable(var_z_data, requires_grad=True)\n",
        "\n",
        "print(new_var_z.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7ipMP1c4u_z",
        "outputId": "ef6e43f3-55e6-48e7-b7bd-df2a01e56cf1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7a576a261240>\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Deep Learning Building Blocks: Affine maps, non-linearities and objectives"
      ],
      "metadata": {
        "id": "P9zoiIZt6B-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin = nn.Linear(5, 3) # maps from R^5 to R^3, parameters A, b\n",
        "data = autograd.Variable( torch.randn(2, 5) ) # data is 2x5.  A maps from 5 to 3... can we map \"data\" under A?\n",
        "print(lin(data)) # yes"
      ],
      "metadata": {
        "id": "IAhp420S5j55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcdd2283-918f-4754-87f1-6a51e5fcf270"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4724,  0.2742,  0.9672],\n",
            "        [-0.2771, -0.2918,  0.4074]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = autograd.Variable(torch.randn(2, 2), requires_grad=True)\n",
        "print(data)\n",
        "print(F.relu(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hOd7C638fa9",
        "outputId": "71d280f5-ab9c-4456-f0f4-72ad20aa75c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.4105, -0.3404],\n",
            "        [-3.0121,  0.5710]], requires_grad=True)\n",
            "tensor([[0.0000, 0.0000],\n",
            "        [0.0000, 0.5710]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax\n",
        "data = autograd.Variable(torch.randn(5), requires_grad=True)\n",
        "print(data)\n",
        "print(F.softmax(data, 0))\n",
        "print(F.softmax(data, 0).sum())\n",
        "print(F.log_softmax(data, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFU_Ucdx8rq0",
        "outputId": "e1223be6-13c9-42ab-834f-6410bce9c2a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.4330,  1.6689,  1.8068, -0.6527,  1.0488], requires_grad=True)\n",
            "tensor([0.2210, 0.2798, 0.3212, 0.0275, 0.1505], grad_fn=<SoftmaxBackward0>)\n",
            "tensor(1.0000, grad_fn=<SumBackward0>)\n",
            "tensor([-1.5095, -1.2736, -1.1357, -3.5952, -1.8937],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Optimization and Training"
      ],
      "metadata": {
        "id": "3ZG_Big0-HRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "there is no code in this section just reading\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CHBNPM7H9tck",
        "outputId": "0ee7a115-6a08-4085-88c4-67278f389bbe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nthere is no code in this section just reading\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Creating Network Components in Pytorch"
      ],
      "metadata": {
        "id": "3nlc98lm-mO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [ (\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
        "         (\"Give it to me\".split(), \"ENGLISH\"),\n",
        "         (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
        "         (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\") ]\n",
        "\n",
        "test_data = [ (\"Yo creo que si\".split(), \"SPANISH\"),\n",
        "              (\"it is lost on me\".split(), \"ENGLISH\")]\n",
        "\n",
        "# word_to_ix maps each word in the vocab to a unique integer, which will be its\n",
        "# index into the Bag of words vector\n",
        "word_to_ix = {}\n",
        "for sent, _ in data + test_data:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "print(word_to_ix)\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "NUM_LABELS = 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4np3ueZh-knS",
        "outputId": "94027c44-a7dc-4fe6-d619-3792bba0028d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'me': 0, 'gusta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'sea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'is': 16, 'not': 17, 'a': 18, 'good': 19, 'get': 20, 'lost': 21, 'at': 22, 'Yo': 23, 'si': 24, 'on': 25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BoWClassifier(nn.Module):\n",
        "    def __init__(self, num_labels, vocab_size):\n",
        "        super(BoWClassifier, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(vocab_size, num_labels)\n",
        "\n",
        "    def forward(self, bow_vec):\n",
        "        return F.log_softmax(self.linear(bow_vec))"
      ],
      "metadata": {
        "id": "iAU5QYqx_eys"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence:\n",
        "        vec[word_to_ix[word]] += 1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_target(label, label_to_ix):\n",
        "    return torch.LongTensor([label_to_ix[label]])"
      ],
      "metadata": {
        "id": "YmURqd6pG1dL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
        "\n",
        "for param in model.parameters():\n",
        "    print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdSJCh4jHSLA",
        "outputId": "652ffe10-6dd8-4a85-978f-6ceb362ccc83"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0929,  0.0079, -0.0402,  0.0651,  0.1697,  0.0579, -0.0632, -0.0962,\n",
            "         -0.1710,  0.1650, -0.0372,  0.0396,  0.0073, -0.1250,  0.1104,  0.1099,\n",
            "          0.0099, -0.1115, -0.0833,  0.0027, -0.1120, -0.1094, -0.0293, -0.0565,\n",
            "          0.0481, -0.0515],\n",
            "        [-0.0260, -0.0749, -0.1792,  0.1710,  0.0374,  0.1754, -0.0316, -0.0493,\n",
            "         -0.1844, -0.0744,  0.1286, -0.1921, -0.0686,  0.1195,  0.1130,  0.0724,\n",
            "         -0.0388, -0.0148, -0.0372, -0.0723,  0.0818, -0.0668, -0.1102,  0.0445,\n",
            "         -0.1418, -0.0419]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.1002, 0.0733], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To run the model, pass in a BoW vector, but wrapped in an autograd.Variable\n",
        "sample = data[0]\n",
        "bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
        "log_probs = model(autograd.Variable(bow_vector, requires_grad=True))\n",
        "print(log_probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "type9x9yHZwn",
        "outputId": "f458c616-9837-4ff5-c433-4aac573ec91a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6489, -0.7394]], grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-56f1c38241ad>:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(self.linear(bow_vec))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_ix = { \"SPANISH\": 0, \"ENGLISH\": 1 }"
      ],
      "metadata": {
        "id": "vGrLMu0hHngk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for instance, label in test_data:\n",
        "    bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix), requires_grad=True)\n",
        "    log_probs = model(bow_vec)\n",
        "    print(log_probs)\n",
        "\n",
        "print(next(model.parameters())[:, word_to_ix[\"creo\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdbeqaKNHySH",
        "outputId": "2f1cfe7d-efc7-4b0f-89d9-d298d7bdf682"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6064, -0.7882]], grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-0.7394, -0.6489]], grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([-0.0372,  0.1286], grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-56f1c38241ad>:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(self.linear(bow_vec))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Usually you want to pass over the training data several times.\n",
        "# 100 is much bigger than on a real data set, but real datasets have more than\n",
        "# two instances.  Usually, somewhere between 5 and 30 epochs is reasonable.\n",
        "for epoch in range(100):\n",
        "    for instance, label in data:\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.  We need to clear them out\n",
        "        # before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Make our BOW vector and also we must wrap the target in a Variable\n",
        "        # as an integer.  For example, if the target is SPANISH, then we wrap the integer\n",
        "        # 0.  The loss function then knows that the 0th element of the log probabilities is\n",
        "        # the log probability corresponding to SPANISH\n",
        "        bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n",
        "        target = autograd.Variable(make_target(label, label_to_ix))\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        log_probs = model(bow_vec)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by calling\n",
        "        # optimizer.step()\n",
        "        loss = loss_function(log_probs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwJlIRJNIUzU",
        "outputId": "30c6af1f-8909-4eef-8077-229d8c8e2d84"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-56f1c38241ad>:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(self.linear(bow_vec))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for instance, label in test_data:\n",
        "    bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix))\n",
        "    log_probs = model(bow_vec)\n",
        "    print(log_probs)\n",
        "print(next(model.parameters())[:,word_to_ix[\"creo\"]]) # Index corresponding to Spanish goes up, English goes down!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8ff5zLJImMc",
        "outputId": "0ee6adf9-0be9-441b-d31b-9c4fff1204bb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1231, -2.1556]], grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([[-2.7641, -0.0651]], grad_fn=<LogSoftmaxBackward0>)\n",
            "tensor([ 0.3847, -0.2932], grad_fn=<SelectBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-56f1c38241ad>:8: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(self.linear(bow_vec))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Word Embeddings: Encoding Lexical Semantics"
      ],
      "metadata": {
        "id": "fAJC-7NJJC6q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "39C_mK0VIt7u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}